{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZs_FPTiZU-6",
        "outputId": "15944056-9129-4748-9224-0b57d424f1a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydantic-evals\n",
            "  Downloading pydantic_evals-1.27.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: anyio>=0 in /usr/local/lib/python3.12/dist-packages (from pydantic-evals) (4.11.0)\n",
            "Collecting logfire-api>=3.14.1 (from pydantic-evals)\n",
            "  Downloading logfire_api-4.16.0-py3-none-any.whl.metadata (972 bytes)\n",
            "Collecting pydantic-ai-slim==1.27.0 (from pydantic-evals)\n",
            "  Downloading pydantic_ai_slim-1.27.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.12/dist-packages (from pydantic-evals) (2.12.3)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from pydantic-evals) (6.0.3)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.12/dist-packages (from pydantic-evals) (13.9.4)\n",
            "Collecting genai-prices>=0.0.40 (from pydantic-ai-slim==1.27.0->pydantic-evals)\n",
            "  Downloading genai_prices-0.0.47-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting griffe>=1.3.2 (from pydantic-ai-slim==1.27.0->pydantic-evals)\n",
            "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-evals) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.28.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-evals) (1.37.0)\n",
            "Collecting pydantic-graph==1.27.0 (from pydantic-ai-slim==1.27.0->pydantic-evals)\n",
            "  Downloading pydantic_graph-1.27.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-evals) (0.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio>=0->pydantic-evals) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=0->pydantic-evals) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio>=0->pydantic-evals) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10->pydantic-evals) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10->pydantic-evals) (2.41.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->pydantic-evals) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.9.4->pydantic-evals) (2.19.2)\n",
            "Collecting colorama>=0.4 (from griffe>=1.3.2->pydantic-ai-slim==1.27.0->pydantic-evals)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.27.0->pydantic-evals) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.27.0->pydantic-evals) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==1.27.0->pydantic-evals) (0.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->pydantic-evals) (0.1.2)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==1.27.0->pydantic-evals) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==1.27.0->pydantic-evals) (3.23.0)\n",
            "Downloading pydantic_evals-1.27.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.2/56.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_ai_slim-1.27.0-py3-none-any.whl (429 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m429.7/429.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_graph-1.27.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.3/72.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading logfire_api-4.16.0-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading genai_prices-0.0.47-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.7/150.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: logfire-api, colorama, griffe, pydantic-graph, genai-prices, pydantic-ai-slim, pydantic-evals\n",
            "Successfully installed colorama-0.4.6 genai-prices-0.0.47 griffe-1.15.0 logfire-api-4.16.0 pydantic-ai-slim-1.27.0 pydantic-evals-1.27.0 pydantic-graph-1.27.0\n",
            "Collecting pydantic-ai\n",
            "  Downloading pydantic_ai-1.27.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: pydantic-ai-slim==1.27.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.27.0)\n",
            "Requirement already satisfied: genai-prices>=0.0.40 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.0.47)\n",
            "Requirement already satisfied: griffe>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.15.0)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.28.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.28.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.37.0)\n",
            "Requirement already satisfied: pydantic-graph==1.27.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.27.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.12.3)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.4.2)\n",
            "Collecting ag-ui-protocol>=0.1.8 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading ag_ui_protocol-0.1.10-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: starlette>=0.45.3 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.48.0)\n",
            "Collecting anthropic>=0.75.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading anthropic-0.75.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting boto3>=1.40.14 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading boto3-1.42.4-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting argcomplete>=3.5.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading argcomplete-3.6.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: prompt-toolkit>=3 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (3.0.52)\n",
            "Requirement already satisfied: pyperclip>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.11.0)\n",
            "Requirement already satisfied: rich>=13 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (13.9.4)\n",
            "Collecting cohere>=5.18.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading cohere-5.20.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: pydantic-evals==1.27.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.27.0)\n",
            "Collecting fastmcp>=2.12.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading fastmcp-2.13.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: google-genai>=1.51.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.52.0)\n",
            "Collecting groq>=0.25.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.36.0)\n",
            "Collecting logfire>=3.14.1 (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading logfire-4.16.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: mcp>=1.18.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.22.0)\n",
            "Collecting mistralai>=1.9.10 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading mistralai-1.9.11-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: openai>=1.107.2 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.8.1)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (9.1.2)\n",
            "Collecting temporalio==1.19.0 (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading temporalio-1.19.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth>=2.36.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.43.0)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.32.4)\n",
            "Requirement already satisfied: anyio>=0 in /usr/local/lib/python3.12/dist-packages (from pydantic-evals==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.11.0)\n",
            "Requirement already satisfied: logfire-api>=3.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic-evals==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.16.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from pydantic-evals==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (6.0.3)\n",
            "Collecting nexus-rpc==1.1.0 (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading nexus_rpc-1.1.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: protobuf<7.0.0,>=3.20 in /usr/local/lib/python3.12/dist-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (5.29.5)\n",
            "Collecting types-protobuf>=3.20 (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading types_protobuf-6.32.1.20251105-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from temporalio==1.19.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.15.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.75.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.75.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.17.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.75.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic>=0.75.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.3.1)\n",
            "Collecting botocore<1.43.0,>=1.42.4 (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading botocore-1.42.4-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.17.0,>=0.16.0 (from boto3>=1.40.14->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading s3transfer-0.16.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
            "Collecting httpx-sse==0.4.0 (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.41.4)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.22.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere>=5.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading types_requests-2.32.4.20250913-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: authlib>=1.6.5 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.6.5)\n",
            "Collecting cyclopts>=4.0.0 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading cyclopts-4.3.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting exceptiongroup>=1.2.2 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading exceptiongroup-1.3.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting jsonschema-path>=0.3.4 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading jsonschema_path-0.3.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting openapi-pydantic>=0.5.1 (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading openapi_pydantic-0.5.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: platformdirs>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.5.0)\n",
            "Collecting py-key-value-aio<0.4.0,>=0.2.8 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading py_key_value_aio-0.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: python-dotenv>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.2.1)\n",
            "Requirement already satisfied: uvicorn>=0.35 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.38.0)\n",
            "Requirement already satisfied: websockets>=15.0.1 in /usr/local/lib/python3.12/dist-packages (from fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (15.0.1)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.9.1)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe>=1.3.2->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.4.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (25.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.5->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (3.13.2)\n",
            "Collecting executing>=2.0.1 (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading executing-2.2.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-http<1.40.0,>=1.39.0 (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation>=0.41b0 (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_instrumentation-0.60b0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting opentelemetry-sdk<1.40.0,>=1.39.0 (from logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-instrumentation-httpx>=0.42b0 (from logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_instrumentation_httpx-0.60b0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.25.1)\n",
            "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.12.0)\n",
            "Requirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from pyjwt[crypto]>=2.10.1->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.10.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (3.0.3)\n",
            "Collecting eval-type-backport>=0.2.0 (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting invoke<3.0.0,>=2.2.0 (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.28.0->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (8.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit>=3->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.2.14)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.10->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.7.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.19.2)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib>=1.6.5->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (43.0.3)\n",
            "Requirement already satisfied: attrs>=23.1.0 in /usr/local/lib/python3.12/dist-packages (from cyclopts>=4.0.0->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (25.4.0)\n",
            "Collecting rich-rst<2.0.0,>=1.3.1 (from cyclopts>=4.0.0->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading rich_rst-1.3.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.28.0->pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (3.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.20.0->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.29.0)\n",
            "Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path>=0.3.4->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading pathable-0.4.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=4.20.0->mcp>=1.18.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.1.2)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http<1.40.0,>=1.39.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.72.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.39.0 (from opentelemetry-exporter-otlp-proto-http<1.40.0,>=1.39.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.39.0 (from opentelemetry-exporter-otlp-proto-http<1.40.0,>=1.39.0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_proto-1.39.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.60b0 (from opentelemetry-instrumentation>=0.41b0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation>=0.41b0->logfire>=3.14.1->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting opentelemetry-api>=1.28.0 (from pydantic-ai-slim==1.27.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_api-1.39.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-util-http==0.60b0 (from opentelemetry-instrumentation-httpx>=0.42b0->logfire[httpx]>=3.14.1; extra == \"logfire\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading opentelemetry_util_http-0.60b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting py-key-value-shared==0.3.0 (from py-key-value-aio<0.4.0,>=0.2.8->py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading py_key_value_shared-0.3.0-py3-none-any.whl.metadata (706 bytes)\n",
            "Requirement already satisfied: beartype>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from py-key-value-aio<0.4.0,>=0.2.8->py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.22.6)\n",
            "Collecting diskcache>=5.0.0 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pathvalidate>=3.3.1 (from py-key-value-aio[disk,memory]<0.4.0,>=0.2.8->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading pathvalidate-3.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.36.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.6.1)\n",
            "Collecting email-validator>=2.0.0 (from pydantic[email]>=2.11.7->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading email_validator-2.3.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->mistralai>=1.9.10->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.17.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.35->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (8.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]<1.0.0,>=0.33.5; extra == \"huggingface\"->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (1.22.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib>=1.6.5->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.0.0)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->pydantic[email]>=2.11.7->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: docutils in /usr/local/lib/python3.12/dist-packages (from rich-rst<2.0.0,>=1.3.1->cyclopts>=4.0.0->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (0.21.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib>=1.6.5->fastmcp>=2.12.0->pydantic-ai-slim[ag-ui,anthropic,bedrock,cli,cohere,evals,fastmcp,google,groq,huggingface,logfire,mcp,mistral,openai,retries,temporal,ui,vertexai]==1.27.0->pydantic-ai) (2.23)\n",
            "Downloading pydantic_ai-1.27.0-py3-none-any.whl (7.2 kB)\n",
            "Downloading temporalio-1.19.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m141.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nexus_rpc-1.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading ag_ui_protocol-0.1.10-py3-none-any.whl (7.9 kB)\n",
            "Downloading anthropic-0.75.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading argcomplete-3.6.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.42.4-py3-none-any.whl (140 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cohere-5.20.0-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.3/303.3 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastmcp-2.13.3-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.6/385.6 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading logfire-4.16.0-py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.1/229.1 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mistralai-1.9.11-py3-none-any.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.42.4-py3-none-any.whl (14.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cyclopts-4.3.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
            "Downloading exceptiongroup-1.3.1-py3-none-any.whl (16 kB)\n",
            "Downloading executing-2.2.1-py2.py3-none-any.whl (28 kB)\n",
            "Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.3/160.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonschema_path-0.3.4-py3-none-any.whl (14 kB)\n",
            "Downloading openapi_pydantic-0.5.1-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_http-1.39.0-py3-none-any.whl (19 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.39.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.39.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation-0.60b0-py3-none-any.whl (33 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.60b0-py3-none-any.whl (219 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.39.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_httpx-0.60b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_util_http-0.60b0-py3-none-any.whl (8.7 kB)\n",
            "Downloading opentelemetry_sdk-1.39.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.4/132.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_key_value_aio-0.3.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.3/96.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py_key_value_shared-0.3.0-py3-none-any.whl (19 kB)\n",
            "Downloading s3transfer-0.16.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_protobuf-6.32.1.20251105-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.4.20250913-py3-none-any.whl (20 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading email_validator-2.3.0-py3-none-any.whl (35 kB)\n",
            "Downloading pathable-0.4.4-py3-none-any.whl (9.6 kB)\n",
            "Downloading pathvalidate-3.3.1-py3-none-any.whl (24 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rich_rst-1.3.2-py3-none-any.whl (12 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, types-requests, types-protobuf, referencing, py-key-value-shared, pathvalidate, pathable, opentelemetry-util-http, opentelemetry-proto, nexus-rpc, jmespath, invoke, httpx-sse, fastavro, executing, exceptiongroup, eval-type-backport, dnspython, diskcache, argcomplete, temporalio, py-key-value-aio, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonschema-path, email-validator, botocore, s3transfer, rich-rst, opentelemetry-semantic-conventions, openapi-pydantic, mistralai, groq, anthropic, ag-ui-protocol, opentelemetry-sdk, opentelemetry-instrumentation, cyclopts, cohere, boto3, opentelemetry-instrumentation-httpx, opentelemetry-exporter-otlp-proto-http, fastmcp, logfire, pydantic-ai\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 2.0.1\n",
            "    Uninstalling wrapt-2.0.1:\n",
            "      Successfully uninstalled wrapt-2.0.1\n",
            "  Attempting uninstall: referencing\n",
            "    Found existing installation: referencing 0.37.0\n",
            "    Uninstalling referencing-0.37.0:\n",
            "      Successfully uninstalled referencing-0.37.0\n",
            "  Attempting uninstall: opentelemetry-proto\n",
            "    Found existing installation: opentelemetry-proto 1.37.0\n",
            "    Uninstalling opentelemetry-proto-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-proto-1.37.0\n",
            "  Attempting uninstall: httpx-sse\n",
            "    Found existing installation: httpx-sse 0.4.3\n",
            "    Uninstalling httpx-sse-0.4.3:\n",
            "      Successfully uninstalled httpx-sse-0.4.3\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.37.0\n",
            "    Uninstalling opentelemetry-api-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.37.0\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.37.0\n",
            "    Uninstalling opentelemetry-sdk-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.37.0\n",
            "  Attempting uninstall: opentelemetry-exporter-otlp-proto-http\n",
            "    Found existing installation: opentelemetry-exporter-otlp-proto-http 1.37.0\n",
            "    Uninstalling opentelemetry-exporter-otlp-proto-http-1.37.0:\n",
            "      Successfully uninstalled opentelemetry-exporter-otlp-proto-http-1.37.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.0 which is incompatible.\n",
            "google-adk 1.19.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ag-ui-protocol-0.1.10 anthropic-0.75.0 argcomplete-3.6.3 boto3-1.42.4 botocore-1.42.4 cohere-5.20.0 cyclopts-4.3.0 diskcache-5.6.3 dnspython-2.8.0 email-validator-2.3.0 eval-type-backport-0.3.1 exceptiongroup-1.3.1 executing-2.2.1 fastavro-1.12.1 fastmcp-2.13.3 groq-0.37.1 httpx-sse-0.4.0 invoke-2.2.1 jmespath-1.0.1 jsonschema-path-0.3.4 logfire-4.16.0 mistralai-1.9.11 nexus-rpc-1.1.0 openapi-pydantic-0.5.1 opentelemetry-api-1.39.0 opentelemetry-exporter-otlp-proto-common-1.39.0 opentelemetry-exporter-otlp-proto-http-1.39.0 opentelemetry-instrumentation-0.60b0 opentelemetry-instrumentation-httpx-0.60b0 opentelemetry-proto-1.39.0 opentelemetry-sdk-1.39.0 opentelemetry-semantic-conventions-0.60b0 opentelemetry-util-http-0.60b0 pathable-0.4.4 pathvalidate-3.3.1 py-key-value-aio-0.3.0 py-key-value-shared-0.3.0 pydantic-ai-1.27.0 referencing-0.36.2 rich-rst-1.3.2 s3transfer-0.16.0 temporalio-1.19.0 types-protobuf-6.32.1.20251105 types-requests-2.32.4.20250913 wrapt-1.17.3\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.8.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ],
      "source": [
        "# install libraries required\n",
        "!pip install pydantic-evals   # evaluation framework\n",
        "!pip install pydantic-ai      # the LLM judge interface\n",
        "!pip install openai           # used as the judge model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load libraries\n",
        "import json\n",
        "import os\n",
        "# from google import genai\n",
        "from google.colab import userdata\n",
        "from pydantic import BaseModel, Field\n",
        "from pydantic_evals.evaluators import Evaluator, EvaluationResult\n",
        "from pydantic_ai import Agent\n"
      ],
      "metadata": {
        "id": "jLQ_9_nwaEMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90f878f4"
      },
      "source": [
        "# import pydantic_evals.evaluators\n",
        "# print(dir(pydantic_evals.evaluators))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32713b9b",
        "outputId": "07196548-e4ca-45e7-e932-11b83ccfcfed"
      },
      "source": [
        "import pydantic_evals\n",
        "print(dir(pydantic_evals))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Case', 'Dataset', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '_utils', 'dataset', 'evaluators', 'increment_eval_metric', 'otel', 'reporting', 'set_eval_attribute']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load input files\n",
        "\n",
        "# load rubric, submission and prompt\n",
        "with open(\"rub_it_0002.json\", \"r\") as f:\n",
        "    rubric_data = json.load(f)\n",
        "\n",
        "# load llm feedback\n",
        "with open(\"FG_Feedback_Results_with_Scores.json\", \"r\") as f:\n",
        "    feedback_data = json.load(f)\n"
      ],
      "metadata": {
        "id": "8chZbtJrZmN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract rubric, submission, and feedback\n",
        "rubric = rubric_data[\"rubric\"][\"criteria\"]\n",
        "student_submission = rubric_data[\"submissions\"][0][\"final_submission\"]\n",
        "llm_feedback = feedback_data[0][\"feedback\"]\n"
      ],
      "metadata": {
        "id": "QMNJV3Uma8lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Rubric: \", rubric, \"\\n\")\n",
        "print(\"Submission: \", student_submission, \"\\n\")\n",
        "print(\"Feedback: \", llm_feedback, \"\\n\")"
      ],
      "metadata": {
        "id": "TVAHv4gWbNp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7b7ad1c-8dc7-4d1f-a77e-a84c7d2c89ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rubric:  [{'criterion_id': 'c1', 'name': 'Conceptual Understanding', 'description': 'Demonstrates deep understanding of the topic and related concepts.', 'performance_descriptors': {'excellent': 'Shows precise and in-depth understanding with clear theoretical support.', 'good': 'Understands key concepts well with minor gaps.', 'average': 'Adequate explanation with some inaccuracies.', 'needs_improvement': 'Surface-level or confused understanding.', 'poor': 'Major misunderstandings or misrepresentations.'}, 'weight': 15}, {'criterion_id': 'c2', 'name': 'Application to Real-World Scenarios', 'description': 'Applies concepts meaningfully to examples or scenarios.', 'performance_descriptors': {'excellent': 'Uses insightful and relevant examples clearly linked to concepts.', 'good': 'Examples mostly appropriate with some gaps in explanation.', 'average': 'Examples present but superficial or unclear connections.', 'needs_improvement': 'Vague or generic examples.', 'poor': 'No real-world application.'}, 'weight': 20}, {'criterion_id': 'c3', 'name': 'Critical Evaluation', 'description': 'Analyzes challenges, limitations, or trade-offs thoughtfully.', 'performance_descriptors': {'excellent': 'Provides insightful, research-backed critical evaluation.', 'good': 'Reasonable evaluation but less depth.', 'average': 'Mentions challenges superficially.', 'needs_improvement': 'Unclear or irrelevant critique.', 'poor': 'No critical evaluation.'}, 'weight': 40}, {'criterion_id': 'c4', 'name': 'Structure and Academic Writing', 'description': 'Quality of writing, flow, citations, and tone.', 'performance_descriptors': {'excellent': 'Clear, coherent, formal tone, flawless grammar, and proper referencing.', 'good': 'Mostly clear and professional; minor issues.', 'average': 'Organization present but inconsistent.', 'needs_improvement': 'Structure or tone hinder clarity; referencing weak.', 'poor': 'Disorganized or informal writing.'}, 'weight': 25}] \n",
            "\n",
            "Submission:  Data breaches continue to affect organisations across industries as systems move online and attackers find new ways to exploit technical and human weaknesses. A large number of these incidents still involve misuse of valid credentials that have been stolen, guessed, or reused across different services. Because of this, multi-factor authentication (MFA) has become a key control for strengthening identity verification. Instead of trusting a password on its own, MFA requires users to prove their identity with two or more different factors, such as a password and a temporary code or biometric check. This essay evaluates how effective MFA is in preventing data breaches, compares common MFA methods and their usability–security trade-offs, and analyses how MFA fits into broader cybersecurity strategies. The argument presented is that MFA is highly effective at blocking many credential-based attacks, but its real-world value depends on the specific methods organisations choose, how consistently they enforce them, and whether usability, fallback mechanisms, and human factors are addressed as part of a wider defence-in-depth approach. Multi-factor authentication reduces the impact of credential compromise by adding additional barriers for attackers. In a single-factor model, a password functions as a single point of failure. If an attacker can obtain it through phishing, malware, or a leaked password database, they can usually log in without further resistance. Breach reports regularly show that such credential-based attacks are one of the most common initial intrusion vectors. By contrast, MFA combines something the user knows with something they have or something they are, meaning an attacker must also control a device—such as a phone, authenticator app, or hardware token—or successfully imitate a biometric factor. From a practical perspective, this layered approach blocks many broad, low-effort attacks. Stolen passwords from one service are less useful if another service requires MFA, because the attacker would also need access to the second factor. Basic phishing emails are also less effective when the password alone no longer grants access. However, the protection provided by MFA is not absolute. Attackers have adapted by targeting the additional factor itself, such as through SIM swapping to intercept text messages or conducting MFA fatigue attacks that bombard users with approval prompts until one is accepted. More advanced adversary-in-the-middle (AiTM) phishing kits proxy the connection between the user and the real service, capturing both the password and the time-based code. These techniques can bypass most mainstream MFA methods except the strongest phishing-resistant options, particularly modern hardware security keys. The security profile of specific MFA methods varies significantly. SMS-based one-time passwords remain widely deployed due to their simplicity and user familiarity. However, telecom infrastructure was not designed with modern threat models in mind. SMS codes are vulnerable to interception via SIM swapping, protocol weaknesses, and phishing, because users can be tricked into entering both their password and the code into a fake website. Authenticator applications using time-based one-time passwords (TOTP) provide stronger protection by generating codes locally and avoiding telecom networks. Compared to SMS codes, authenticator apps significantly reduce exposure to telecom-level attacks, though both remain phishable and vulnerable to AiTM techniques. Usability challenges also appear, such as device loss or migration issues. Push-based MFA improves usability by enabling users to approve logins with a tap instead of transcribing a code. While this reduces friction and can increase adoption, it introduces behavioural risks. Attackers increasingly exploit MFA fatigue attacks, relying on users becoming desensitised to repeated prompts. In these cases, the limitation is not the technology but human behaviour. If users develop poor “prompt hygiene”—approving notifications without scrutiny—the value of the second factor diminishes. Hardware security keys represent the strongest tier of MFA. They use public key cryptography and bind authentication to the legitimate website or application, making them resistant to phishing and adversary-in-the-middle attacks. Even if a user interacts with a convincing fake login page, the hardware key refuses to authenticate because the domain does not match the registered origin. This makes hardware keys the most effective option for high-risk accounts. Biometrics also offer convenience and strong assurance but raise privacy concerns and difficulties related to revocation, since biometric traits cannot be replaced. A clearer tiered model therefore emerges: SMS codes at the weaker end, authenticator apps and push MFA in the moderate middle, and hardware keys and hardware-bound biometrics at the strong, phishing-resistant end. Yet even strong MFA can be undermined by organisational decisions. Real-world breaches often occur not because MFA is inherently weak, but because it is optional instead of mandatory, inconsistently applied across systems, or weakened by insecure fallback methods such as SMS recovery codes or email resets. Moreover, if high-assurance authentication is implemented but users revert to insecure recovery processes, the overall posture weakens. The effectiveness of MFA therefore depends not only on the chosen method but also on configuration, enforcement, and policy design. These issues highlight the crucial role of human factors. Organisations must ensure users understand phishing risks, MFA fatigue, and the importance of verifying prompt legitimacy. A technically strong MFA system can still fail if users habitually approve unexpected requests. Security culture, training, and clear communication are therefore essential to unlocking the full value of MFA. To address these challenges, MFA must operate within a broader cybersecurity strategy rather than as a standalone control. Under a zero-trust model, no user or device is trusted by default. Authentication and authorisation decisions rely on multiple continuous signals, including identity, device posture, behavioural analytics, and contextual risk. MFA contributes one signal within this ecosystem but does not prevent lateral movement once an attacker is already inside the network. Complementary measures—such as conditional access policies, privileged access management (PAM), network segmentation, and continuous monitoring—are required to form a cohesive identity-centric defence. Adaptive or risk-based MFA further enhances integration by tailoring authentication requirements to the context of each login attempt. By stepping up security only when behaviour appears unusual (for example, from an unknown location or unmanaged device), adaptive MFA reduces fatigue and improves usability without lowering security expectations. This reflects modern identity frameworks such as NIST SP 800-63, which emphasise assurance levels appropriate to risk. Likewise, regulatory and industry frameworks such as PCI DSS and ISO 27001 require MFA for sensitive environments, demonstrating that MFA’s role is not only technical but also compliance-driven. Looking forward, MFA also plays a transitional role in the shift toward passwordless authentication, where hardware-bound credentials and biometrics replace passwords entirely. As organisations adopt these approaches, MFA becomes part of a broader movement away from passwords as the primary security mechanism. In conclusion, multi-factor authentication is a highly effective control for reducing the risk of data breaches caused by compromised credentials. By requiring additional proof of identity beyond a password, MFA blocks many common attack paths and forces attackers to invest more effort and resources. However, its impact depends on method selection, configuration, user behaviour, and organisational policy. When embedded within a wider defence-in-depth strategy, supported by standards and complemented by continuous risk assessment, MFA becomes a central component of modern cybersecurity. Careful implementation, consistent enforcement, and strong human-centred design ensure that MFA delivers its intended protection against increasingly sophisticated credential-based attacks. \n",
            "\n",
            "Feedback:  EDUCATOR FEEDBACK & ACTIONABLE INSIGHTS\n",
            "The student demonstrates a strong learning process by actively seeking to understand the nuances of MFA, as evidenced by their detailed prompts exploring various methods, their trade-offs, and integration into broader strategies. The engagement level is high, consistently probing for deeper insights. To further enhance their learning, the student could explore specific case studies of data breaches where MFA was either effective or bypassed, and investigate the evolving landscape of MFA bypass techniques and countermeasures. This would deepen their critical evaluation and real-world application.\n",
            "\n",
            "RUBRIC SCORES\n",
            "Conceptual Understanding: 10/10 - The student's prompts show a comprehensive grasp of MFA, its components, and its role in cybersecurity, demonstrating deep theoretical understanding.\n",
            "Application to Real-World Scenarios: 9/10 - The student effectively prompts for comparisons of MFA methods and their integration into strategies, indicating a strong ability to apply concepts to practical scenarios.\n",
            "Critical Evaluation: 10/10 - The student consistently pushes for an analysis of trade-offs, limitations, and evolving attack vectors, showcasing excellent critical thinking and evaluation skills.\n",
            "Structure and Academic Writing: 10/10 - The student's prompts are clear, well-articulated, and directly address the assignment's requirements, indicating strong organizational and communication skills. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the meta-rubric for the llm judge\n",
        "\n",
        "META_RUBRIC = \"\"\"\n",
        "ou must evaluate the **quality** of the feedback produced by an LLM.\n",
        "\n",
        "Evaluate the feedback only using the following meta-rubric:\n",
        "\n",
        "### META-RUBRIC\n",
        "\n",
        "1. **Accuracy**\n",
        "   Does the feedback correctly reflect the student’s submission?\n",
        "\n",
        "2. **Specificity**\n",
        "   Is the feedback concrete, detailed, and supported with examples rather than vague advice?\n",
        "\n",
        "3. **Constructiveness**\n",
        "   Does the feedback guide the student on how to improve?\n",
        "\n",
        "4. **Alignment with assignment rubric**\n",
        "   Does the feedback clearly reference (and stay aligned with) the criteria used to judge the work?\n",
        "\n",
        "5. **Tone and clarity**\n",
        "   Is the feedback easy to understand, supportive, and professionally written?\n",
        "\n",
        "### SCORING INSTRUCTIONS\n",
        "For each dimension, give a score from **0 to 10** and provide a justification.\n",
        "Then provide an overall score and a summary.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "Lg_sE24mbuIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a sub-model for a single rubric criterion\n",
        "class CriterionResult(BaseModel):\n",
        "    score: int = Field(..., description=\"The score (0-10) for this dimension.\")\n",
        "    explanation: str = Field(..., description=\"The justification for the score.\")"
      ],
      "metadata": {
        "id": "5LU-bidVBv35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the main output model with explicit fields for each criterion\n",
        "class JudgeOutput(BaseModel):\n",
        "    accuracy: CriterionResult\n",
        "    specificity: CriterionResult\n",
        "    constructiveness: CriterionResult\n",
        "    alignment: CriterionResult\n",
        "    tone_clarity: CriterionResult\n",
        "\n",
        "    overall_score: float = Field(\n",
        "        ...,\n",
        "        description=\"The average of the five scores, rounded to one decimal place.\"\n",
        "    )\n",
        "    summary: str = Field(\n",
        "        ...,\n",
        "        description=\"A short summary of the feedback's strengths and weaknesses.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "40LNiT7J9aWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the llm-as-judge evaluator\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "print(\"API Key set:\", os.environ.get('OPENAI_API_KEY') is not None)\n",
        "\n",
        "# judge = Agent(model=\"gpt-5-mini, retries=3\")\n",
        "judge = Agent(model=\"gpt-5-mini\")\n",
        "\n",
        "class MetaRubricEvaluator(Evaluator):\n",
        "\n",
        "    async def evaluate(self, case):\n",
        "        prompt = f\"\"\"\n",
        "You are an expert academic evaluator.\n",
        "\n",
        "The student's submission is:\n",
        "--------------------\n",
        "{student_submission}\n",
        "--------------------\n",
        "\n",
        "The feedback you must evaluate is:\n",
        "--------------------\n",
        "{llm_feedback}\n",
        "--------------------\n",
        "\n",
        "Use the following meta-rubric:\n",
        "{META_RUBRIC}\n",
        "\n",
        "Now score the feedback strictly according to the meta-rubric.\n",
        "\"\"\"\n",
        "        result = await judge.run(\n",
        "            prompt,\n",
        "            output_type=JudgeOutput # Pass the schema for structured output\n",
        "        )\n",
        "        # return EvaluationResult(model_output=result.output)\n",
        "        return EvaluationResult(\n",
        "            name=\"Meta_Rubric_Score\", # Required field\n",
        "            value=result.output.overall_score, # Extract the scalar score\n",
        "            reason=result.output.summary, # Extract the summary as the reason\n",
        "            source=judge.model.model_name\n",
        "        )"
      ],
      "metadata": {
        "id": "ZE6BBbAHdCp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92cdec26-5fd2-4f71-ac4d-ee9477dc6b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API Key set: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run the evaluation\n",
        "\n",
        "evaluator = MetaRubricEvaluator()\n",
        "\n",
        "case = {\"id\": \"case1\"}\n",
        "result = await evaluator.evaluate(case)\n",
        "result\n"
      ],
      "metadata": {
        "id": "8hN80Z6lhZ2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97973e72-ddba-474f-91e2-17d53f0deec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EvaluationResult(name='Meta_Rubric_Score', value=8.4, reason=\"Strengths: The feedback is positive, aligned with the rubric, and offers a clear, actionable next step (investigate case studies and bypass techniques). It also scores the student's performance across appropriate categories and maintains a supportive tone. Weaknesses: The feedback occasionally mislabels the submission as 'prompts' instead of an essay, and it is light on concrete examples and specific resources or revision tasks. To improve, the educator should cite brief examples from the submission to justify each rubric score and recommend specific case studies or readings the student could examine.\", source='gpt-5-mini')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # print full result\n",
        "# print(\"\\nFull Result Object:\")\n",
        "# print(result)\n",
        "\n",
        "# pring score and reason\n",
        "print(f\"Score: {result.value}\")\n",
        "print(\"Reason:\")\n",
        "result.reason\n"
      ],
      "metadata": {
        "id": "Cb5T73aMEz5L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5a531603-c525-4c6a-f240-28dce1899e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 8.4\n",
            "Reason:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Strengths: The feedback is positive, aligned with the rubric, and offers a clear, actionable next step (investigate case studies and bypass techniques). It also scores the student's performance across appropriate categories and maintains a supportive tone. Weaknesses: The feedback occasionally mislabels the submission as 'prompts' instead of an essay, and it is light on concrete examples and specific resources or revision tasks. To improve, the educator should cite brief examples from the submission to justify each rubric score and recommend specific case studies or readings the student could examine.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}